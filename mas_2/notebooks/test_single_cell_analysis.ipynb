{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# å•ç»†èƒæ•°æ®åˆ†æä¸ç»†èƒæ ‡æ³¨æµ‹è¯•\n",
        "\n",
        "## æµ‹è¯•ç”¨ä¾‹è¯´æ˜\n",
        "\n",
        "æœ¬ notebook æµ‹è¯•ä¸€ä¸ªå®Œæ•´çš„å•ç»†èƒæ•°æ®åˆ†ææµç¨‹ï¼š\n",
        "\n",
        "1. **Supervisor** é€‰æ‹© `code_dev` agent\n",
        "2. **Code Dev Agent** æ‰§è¡Œå•ç»†èƒæ•°æ®åˆ†æï¼š\n",
        "   - ç”Ÿæˆ Scanpy ä»£ç \n",
        "   - è¿è¡Œå¾—åˆ° UMAP å¯è§†åŒ–\n",
        "   - è¿›è¡Œ Leiden èšç±»\n",
        "   - åœ¨æ¯ä¸ªèšç±»ä¸Šåšå·®å¼‚è¡¨è¾¾åˆ†æï¼ˆDEï¼‰\n",
        "   - è¿”å›æ¯ä¸ªèšç±»çš„ top DE åŸºå› \n",
        "3. **Supervisor** é€‰æ‹© `tool_caller` agent\n",
        "4. **Tool Caller Agent** ä½¿ç”¨ç»†èƒç±»å‹æ³¨é‡Šå·¥å…·ï¼Œæ ¹æ® DE åŸºå› ç¡®å®šç»†èƒç±»å‹\n",
        "5. **Supervisor** å†æ¬¡é€‰æ‹© `code_dev` agent\n",
        "6. **Code Dev Agent** ä½¿ç”¨ç¡®å®šçš„ç»†èƒç±»å‹è¿›è¡Œæ ‡æ³¨\n",
        "\n",
        "## é¢„æœŸç»“æœ\n",
        "\n",
        "- UMAP å¯è§†åŒ–å›¾\n",
        "- Leiden èšç±»ç»“æœ\n",
        "- æ¯ä¸ªèšç±»çš„ç»†èƒç±»å‹æ ‡æ³¨\n",
        "- å·®å¼‚è¡¨è¾¾åŸºå› åˆ—è¡¨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. å¯¼å…¥å¿…è¦çš„åº“\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "from typing import Dict, Any\n",
        "\n",
        "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# å¯¼å…¥ä¸»å›¾\n",
        "from src.main import graph\n",
        "from langchain_core.messages import HumanMessage\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-5fc57b6172c548239d6911ae1b528cd4\"\n",
        "\n",
        "# proxy_vars = [\"HTTP_PROXY\", \"HTTPS_PROXY\", \"ALL_PROXY\", \"http_proxy\", \"https_proxy\", \"all_proxy\"]\n",
        "\n",
        "# for var in proxy_vars:\n",
        "#     if var in os.environ:\n",
        "#         del os.environ[var]\n",
        "#         print(f\"å·²æ¸…é™¤ç¯å¢ƒå˜é‡: {var}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å‡†å¤‡åˆå§‹çŠ¶æ€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… åˆå§‹çŠ¶æ€å‡†å¤‡å®Œæˆ\n",
            "ç”¨æˆ·æŸ¥è¯¢: \n",
            "è¯·å¯¹å•ç»†èƒæ•°æ®è¿›è¡Œä»¥ä¸‹åˆ†æï¼š\n",
            "1. è¯»å–æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†ï¼ˆQCã€æ ‡å‡†åŒ–ï¼‰\n",
            "2. è¿›è¡Œ PCA é™ç»´\n",
            "3. è®¡ç®— UMAP å¯è§†åŒ–\n",
            "4. ä½¿ç”¨ Leiden ç®—æ³•è¿›è¡Œèšç±»\n",
            "5. å¯¹æ¯ä¸ªèšç±»è¿›è¡Œå·®å¼‚è¡¨è¾¾...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:11: SyntaxWarning: invalid escape sequence '\\F'\n",
            "<>:11: SyntaxWarning: invalid escape sequence '\\F'\n",
            "C:\\Users\\Minghao\\AppData\\Local\\Temp\\ipykernel_15092\\217540408.py:11: SyntaxWarning: invalid escape sequence '\\F'\n",
            "  æ•°æ®è·¯å¾„ï¼šr\"D:\\Files\\2026\\RES-2026_01-Agent-GWAS\\Code\\mas\\mas_2\\data\"\n"
          ]
        }
      ],
      "source": [
        "# å®šä¹‰å•ç»†èƒæ•°æ®åˆ†æä»»åŠ¡\n",
        "user_query = \"\"\"\n",
        "è¯·å¯¹å•ç»†èƒæ•°æ®è¿›è¡Œä»¥ä¸‹åˆ†æï¼š\n",
        "1. è¯»å–æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†ï¼ˆQCã€æ ‡å‡†åŒ–ï¼‰\n",
        "2. è¿›è¡Œ PCA é™ç»´\n",
        "3. è®¡ç®— UMAP å¯è§†åŒ–\n",
        "4. ä½¿ç”¨ Leiden ç®—æ³•è¿›è¡Œèšç±»\n",
        "5. å¯¹æ¯ä¸ªèšç±»è¿›è¡Œå·®å¼‚è¡¨è¾¾åˆ†æï¼Œæ‰¾å‡ºæ¯ä¸ªèšç±»çš„ top 10 å·®å¼‚è¡¨è¾¾åŸºå› \n",
        "6. è¿”å›æ¯ä¸ªèšç±»çš„å·®å¼‚è¡¨è¾¾åŸºå› åˆ—è¡¨\n",
        "\n",
        "æ•°æ®è·¯å¾„ï¼š\"D:\\\\Files\\\\2026\\\\RES-2026_01-Agent-GWAS\\\\Code\\\\mas\\\\mas_2\\\\data\"\n",
        "è¾“å‡ºè·¯å¾„ï¼š\"D:\\\\Files\\\\2026\\\\RES-2026_01-Agent-GWAS\\\\Code\\\\mas\\\\mas_2\\\\results\"\n",
        "\"\"\"\n",
        "\n",
        "# åˆå§‹åŒ–çŠ¶æ€\n",
        "initial_state = {\n",
        "    \"messages\": [HumanMessage(content=user_query)],\n",
        "    \"user_query\": user_query.strip(),\n",
        "    \"next_worker\": \"rag_researcher\",  # åˆå§‹å€¼ï¼Œä¼šè¢« Supervisor è¦†ç›–\n",
        "    \"last_worker\": \"\",\n",
        "    \"final_report\": \"\",\n",
        "    \"code_solution\": \"\",\n",
        "    \"rag_context\": \"\",\n",
        "    \"pending_contribution\": None,\n",
        "    \"critique_feedback\": None,\n",
        "    \"is_approved\": False,\n",
        "}\n",
        "\n",
        "print(\"âœ… åˆå§‹çŠ¶æ€å‡†å¤‡å®Œæˆ\")\n",
        "print(f\"ç”¨æˆ·æŸ¥è¯¢: {user_query[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. è¿è¡Œä¸»å›¾å¹¶è·Ÿè¸ªæ‰§è¡Œæµç¨‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ å¼€å§‹æ‰§è¡Œä¸»å›¾...\n",
            "============================================================\n",
            "--- [Supervisor] æ­£åœ¨åšè°ƒåº¦å†³ç­– ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  --> å†³ç­–: code_dev\n",
            "  --> ç†ç”±: å½“å‰ä»»åŠ¡æ˜¯å®Œæˆå•ç»†èƒæ•°æ®åˆ†ææµç¨‹ï¼ˆQCã€æ ‡å‡†åŒ–ã€PCAã€UMAPã€Leidenèšç±»ã€å·®å¼‚è¡¨è¾¾åˆ†æåŠtop10åŸºå› æå–ï¼‰ï¼Œç”¨æˆ·å·²æ˜ç¡®æä¾›è¾“å…¥è·¯å¾„å’Œè¾“å‡ºè·¯å¾„ï¼Œä¸”æ— ç‰¹æ®Šæ–‡çŒ®ä¾èµ–æˆ–æ¨¡ç³Šæ¦‚å¿µéœ€è¦æ¾„æ¸…ã€‚RAGä¸Šä¸‹æ–‡ä¸º'æœªè·å–'ï¼Œä½†è¯¥ä»»åŠ¡å±äºæ ‡å‡†å•ç»†èƒåˆ†ææµç¨‹ï¼ˆSeurat/Scanpy å¸¸è§èŒƒå¼ï¼‰ï¼Œæ— éœ€é¢å¤–æ–‡çŒ®æ”¯æ’‘â€”â€”ç°æœ‰ç”Ÿç‰©ä¿¡æ¯å­¦æœ€ä½³å®è·µå·²é«˜åº¦æˆç†Ÿã€å¯ç›´æ¥ç¼–ç å®ç°ï¼›åŒæ—¶ï¼Œå°šæœªç”Ÿæˆä»»ä½•ä»£ç ï¼Œä¹Ÿæ— å¾…å®¡æ ¸å†…å®¹ï¼Œå› æ­¤ä¸æ»¡è¶³è°ƒç”¨ rag_researcherï¼ˆæ— æ£€ç´¢å¿…è¦ï¼‰ã€criticï¼ˆæ— å¯å®¡å†…å®¹ï¼‰æˆ– tool_callerï¼ˆæ— éœ€å¤–éƒ¨å·¥å…·è°ƒç”¨ï¼Œå…¨éƒ¨åˆ†æéœ€å®šåˆ¶åŒ–è„šæœ¬æ‰§è¡Œï¼‰ã€‚code_dev æ˜¯å”¯ä¸€èƒ½æ¨è¿›ä»»åŠ¡çš„å…³é”®èŠ‚ç‚¹ï¼šå®ƒå°†åŸºäºè·¯å¾„ã€æ­¥éª¤å’Œè§„èŒƒè¦æ±‚ï¼Œç”Ÿæˆå¯è¿è¡Œã€æ¨¡å—åŒ–ã€å¸¦é”™è¯¯å¤„ç†ä¸æ—¥å¿—çš„å®Œæ•´åˆ†æä»£ç ï¼ˆå»ºè®®ä½¿ç”¨ Scanpy + Pythonï¼Œå…¼é¡¾å¯å¤ç°æ€§ä¸ç”Ÿæ€å…¼å®¹æ€§ï¼‰ã€‚\n",
            "\n",
            "ğŸ“Œ [1] æ‰§è¡ŒèŠ‚ç‚¹: supervisor\n",
            "   â†’ next_worker: code_dev\n",
            "   â†’ last_worker: \n",
            "   â†’ is_approved: False\n",
            "--- [Code Dev] æ­£åœ¨ç”Ÿæˆä»£ç  (è¿­ä»£ 1) ---\n",
            "  --> è­¦å‘Šï¼šè§£æåˆ°çš„æ•°æ®è·¯å¾„ä¸å­˜åœ¨: r\"D:\\FilesÂ‚6\\RES-2026_01-Agent-GWAS\\Code\\mas\\mas_2\\data\n",
            "esultsä»ç”¨æˆ·æŸ¥è¯¢ä¸­è§£æåˆ°ç»“æœè·¯å¾„: r\"D:\\FilesÂ‚6\\RES-2026_01-Agent-GWAS\\Code\\mas\\mas_2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  --> ä»£ç ç”ŸæˆæˆåŠŸï¼Œä»£ç é•¿åº¦: 5988 å­—ç¬¦\n",
            "--- [Code Dev] è¿›è¡Œè‡ªæˆ‘æ£€æŸ¥ ---\n",
            "--- [Code Dev] æ­£åœ¨æ‰§è¡Œä»£ç  ---\n",
            "\n",
            "âŒ æ‰§è¡Œå‡ºé”™: [WinError 123] æ–‡ä»¶åã€ç›®å½•åæˆ–å·æ ‡è¯­æ³•ä¸æ­£ç¡®ã€‚: 'r\"D:'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Minghao\\AppData\\Local\\Temp\\ipykernel_15092\\1463509198.py\", line 9, in <module>\n",
            "    for step in graph.stream(initial_state, config={\"recursion_limit\": max_steps}):\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\pregel\\main.py\", line 2646, in stream\n",
            "    for _ in runner.tick(\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\pregel\\_runner.py\", line 167, in tick\n",
            "    run_with_retry(\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\pregel\\_retry.py\", line 42, in run_with_retry\n",
            "    return task.proc.invoke(task.input, config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 656, in invoke\n",
            "    input = context.run(step.invoke, input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
            "    ret = self.func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"D:\\Files\\2026\\RES-2026_01-Agent-GWAS\\Code\\mas\\mas_2\\src\\main.py\", line 29, in wrap_code_dev\n",
            "    result = code_agent_graph.invoke(state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\pregel\\main.py\", line 3071, in invoke\n",
            "    for chunk in self.stream(\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\pregel\\main.py\", line 2646, in stream\n",
            "    for _ in runner.tick(\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\pregel\\_runner.py\", line 167, in tick\n",
            "    run_with_retry(\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\pregel\\_retry.py\", line 42, in run_with_retry\n",
            "    return task.proc.invoke(task.input, config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 656, in invoke\n",
            "    input = context.run(step.invoke, input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Minghao\\.conda\\envs\\langchain\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
            "    ret = self.func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"D:\\Files\\2026\\RES-2026_01-Agent-GWAS\\Code\\mas\\mas_2\\src\\agents\\code_dev\\graph.py\", line 291, in execute_code\n",
            "    os.makedirs(result_path, exist_ok=True)\n",
            "  File \"<frozen os>\", line 215, in makedirs\n",
            "  File \"<frozen os>\", line 215, in makedirs\n",
            "  File \"<frozen os>\", line 215, in makedirs\n",
            "  [Previous line repeated 2 more times]\n",
            "  File \"<frozen os>\", line 225, in makedirs\n",
            "OSError: [WinError 123] æ–‡ä»¶åã€ç›®å½•åæˆ–å·æ ‡è¯­æ³•ä¸æ­£ç¡®ã€‚: 'r\"D:'\n",
            "During task with name 'execute_code' and id '46ed3f24-de34-9e17-8feb-dda336c54e73'\n",
            "During task with name 'code_dev' and id '2307f4c0-7f52-fc7c-8190-43ae18e59812'\n"
          ]
        }
      ],
      "source": [
        "# ä½¿ç”¨ stream æ¥è·Ÿè¸ªæ‰§è¡Œæµç¨‹\n",
        "execution_steps = []\n",
        "max_steps = 30  # è®¾ç½®æœ€å¤§æ­¥æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯\n",
        "\n",
        "print(\"ğŸš€ å¼€å§‹æ‰§è¡Œä¸»å›¾...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    for step in graph.stream(initial_state, config={\"recursion_limit\": max_steps}):\n",
        "        for node_name, node_state in step.items():\n",
        "            execution_steps.append({\n",
        "                \"node\": node_name,\n",
        "                \"state\": node_state.copy()\n",
        "            })\n",
        "            \n",
        "            print(f\"\\nğŸ“Œ [{len(execution_steps)}] æ‰§è¡ŒèŠ‚ç‚¹: {node_name}\")\n",
        "            \n",
        "            # æ˜¾ç¤ºå…³é”®çŠ¶æ€ä¿¡æ¯\n",
        "            if \"next_worker\" in node_state:\n",
        "                print(f\"   â†’ next_worker: {node_state['next_worker']}\")\n",
        "            if \"last_worker\" in node_state:\n",
        "                print(f\"   â†’ last_worker: {node_state['last_worker']}\")\n",
        "            if \"is_approved\" in node_state:\n",
        "                print(f\"   â†’ is_approved: {node_state['is_approved']}\")\n",
        "            if \"pending_contribution\" in node_state and node_state.get(\"pending_contribution\"):\n",
        "                pending = node_state[\"pending_contribution\"]\n",
        "                if isinstance(pending, dict) and \"code\" in pending:\n",
        "                    code_preview = pending[\"code\"][:200] if len(pending[\"code\"]) > 200 else pending[\"code\"]\n",
        "                    print(f\"   â†’ ç”Ÿæˆçš„ä»£ç é¢„è§ˆ: {code_preview}...\")\n",
        "            \n",
        "            # å¦‚æœåˆ°è¾¾ finalizeï¼Œåœæ­¢\n",
        "            if node_name == \"finalize\":\n",
        "                print(\"\\nâœ… åˆ°è¾¾ Finalize èŠ‚ç‚¹ï¼Œä»»åŠ¡å®Œæˆ\")\n",
        "                break\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"âœ… æ‰§è¡Œå®Œæˆï¼Œå…±æ‰§è¡Œ {len(execution_steps)} æ­¥\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ æ‰§è¡Œå‡ºé”™: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. æå–æœ€ç»ˆç»“æœ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š æœ€ç»ˆçŠ¶æ€æ‘˜è¦:\n",
            "============================================================\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# è·å–æœ€ç»ˆçŠ¶æ€\n",
        "if execution_steps:\n",
        "    final_state = execution_steps[-1][\"state\"]\n",
        "    \n",
        "    print(\"ğŸ“Š æœ€ç»ˆçŠ¶æ€æ‘˜è¦:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ\n",
        "    if \"final_answer\" in final_state:\n",
        "        print(f\"\\nğŸ“ æœ€ç»ˆç­”æ¡ˆ:\\n{final_state['final_answer']}\")\n",
        "    \n",
        "    # æ˜¾ç¤ºä»£ç è§£å†³æ–¹æ¡ˆ\n",
        "    if final_state.get(\"code_solution\"):\n",
        "        print(f\"\\nğŸ’» ä»£ç è§£å†³æ–¹æ¡ˆ:\\n{final_state['code_solution'][:500]}...\")\n",
        "    \n",
        "    # æ˜¾ç¤º RAG ä¸Šä¸‹æ–‡\n",
        "    if final_state.get(\"rag_context\"):\n",
        "        print(f\"\\nğŸ“š RAG ä¸Šä¸‹æ–‡:\\n{final_state['rag_context'][:300]}...\")\n",
        "    \n",
        "    # æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š\n",
        "    if final_state.get(\"final_report\"):\n",
        "        print(f\"\\nğŸ“„ æœ€ç»ˆæŠ¥å‘Š:\\n{final_state['final_report'][:500]}...\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "else:\n",
        "    print(\"âš ï¸ æ²¡æœ‰æ‰§è¡Œæ­¥éª¤è®°å½•\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. åˆ†ææ‰§è¡Œæµç¨‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ æ‰§è¡Œæµç¨‹åˆ†æ:\n",
            "============================================================\n",
            "\n",
            "èŠ‚ç‚¹æ‰§è¡Œé¡ºåº: supervisor\n",
            "\n",
            "å„èŠ‚ç‚¹æ‰§è¡Œæ¬¡æ•°:\n",
            "  - supervisor: 1 æ¬¡\n",
            "\n",
            "ğŸ” å…³é”®æ­¥éª¤:\n"
          ]
        }
      ],
      "source": [
        "# åˆ†ææ‰§è¡Œæµç¨‹\n",
        "print(\"ğŸ”„ æ‰§è¡Œæµç¨‹åˆ†æ:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "node_sequence = [step[\"node\"] for step in execution_steps]\n",
        "print(f\"\\nèŠ‚ç‚¹æ‰§è¡Œé¡ºåº: {' -> '.join(node_sequence)}\")\n",
        "\n",
        "# ç»Ÿè®¡å„èŠ‚ç‚¹æ‰§è¡Œæ¬¡æ•°\n",
        "from collections import Counter\n",
        "node_counts = Counter(node_sequence)\n",
        "print(f\"\\nå„èŠ‚ç‚¹æ‰§è¡Œæ¬¡æ•°:\")\n",
        "for node, count in node_counts.items():\n",
        "    print(f\"  - {node}: {count} æ¬¡\")\n",
        "\n",
        "# æŸ¥æ‰¾å…³é”®æ­¥éª¤\n",
        "print(\"\\nğŸ” å…³é”®æ­¥éª¤:\")\n",
        "for i, step in enumerate(execution_steps):\n",
        "    node = step[\"node\"]\n",
        "    state = step[\"state\"]\n",
        "    \n",
        "    # Code Dev ç”Ÿæˆä»£ç \n",
        "    if node == \"code_dev\" and state.get(\"pending_contribution\"):\n",
        "        pending = state[\"pending_contribution\"]\n",
        "        if isinstance(pending, dict) and \"code\" in pending:\n",
        "            print(f\"\\n  [{i+1}] Code Dev ç”Ÿæˆä»£ç  (æ­¥éª¤ {i+1})\")\n",
        "            print(f\"      ä»£ç é•¿åº¦: {len(pending['code'])} å­—ç¬¦\")\n",
        "    \n",
        "    # Tool Caller è°ƒç”¨å·¥å…·\n",
        "    if node == \"tool_caller\" and state.get(\"tool_name\"):\n",
        "        print(f\"\\n  [{i+1}] Tool Caller è°ƒç”¨å·¥å…·: {state['tool_name']} (æ­¥éª¤ {i+1})\")\n",
        "        if state.get(\"tool_result\"):\n",
        "            result_preview = str(state[\"tool_result\"])[:200]\n",
        "            print(f\"      ç»“æœé¢„è§ˆ: {result_preview}...\")\n",
        "    \n",
        "    # Critic å®¡æ ¸ç»“æœ\n",
        "    if node == \"critic\":\n",
        "        is_approved = state.get(\"is_approved\", False)\n",
        "        status = \"âœ… é€šè¿‡\" if is_approved else \"âŒ é©³å›\"\n",
        "        print(f\"\\n  [{i+1}] Critic å®¡æ ¸: {status} (æ­¥éª¤ {i+1})\")\n",
        "        if state.get(\"critique_feedback\"):\n",
        "            feedback = state[\"critique_feedback\"][:200]\n",
        "            print(f\"      åé¦ˆ: {feedback}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. æå–ä»£ç å’Œç»“æœ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ æ‰¾åˆ° 0 æ®µç”Ÿæˆçš„ä»£ç \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# æå–æ‰€æœ‰ç”Ÿæˆçš„ä»£ç \n",
        "generated_codes = []\n",
        "\n",
        "for step in execution_steps:\n",
        "    state = step[\"state\"]\n",
        "    \n",
        "    # ä» pending_contribution æå–ä»£ç \n",
        "    if state.get(\"pending_contribution\"):\n",
        "        pending = state[\"pending_contribution\"]\n",
        "        if isinstance(pending, dict) and \"code\" in pending:\n",
        "            generated_codes.append({\n",
        "                \"step\": step[\"node\"],\n",
        "                \"code\": pending[\"code\"]\n",
        "            })\n",
        "    \n",
        "    # ä» code_solution æå–ä»£ç \n",
        "    if state.get(\"code_solution\"):\n",
        "        generated_codes.append({\n",
        "            \"step\": \"code_solution\",\n",
        "            \"code\": state[\"code_solution\"]\n",
        "        })\n",
        "\n",
        "print(f\"ğŸ“ æ‰¾åˆ° {len(generated_codes)} æ®µç”Ÿæˆçš„ä»£ç \\n\")\n",
        "\n",
        "for i, code_info in enumerate(generated_codes, 1):\n",
        "    print(f\"ä»£ç æ®µ {i} (æ¥æº: {code_info['step']}):\")\n",
        "    print(\"-\" * 60)\n",
        "    print(code_info[\"code\"][:500])\n",
        "    if len(code_info[\"code\"]) > 500:\n",
        "        print(\"...\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. æå–ç»†èƒç±»å‹æ ‡æ³¨ç»“æœ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ æœªæ‰¾åˆ°ç»†èƒç±»å‹æ³¨é‡Šç»“æœ\n"
          ]
        }
      ],
      "source": [
        "# æŸ¥æ‰¾ Tool Caller çš„ç»†èƒç±»å‹æ³¨é‡Šç»“æœ\n",
        "celltype_results = []\n",
        "\n",
        "for step in execution_steps:\n",
        "    state = step[\"state\"]\n",
        "    \n",
        "    # æŸ¥æ‰¾ tool_caller çš„ç»“æœ\n",
        "    if step[\"node\"] == \"tool_caller\":\n",
        "        tool_result = state.get(\"tool_result\")\n",
        "        if tool_result and isinstance(tool_result, dict):\n",
        "            # æ£€æŸ¥æ˜¯å¦æ˜¯ç»†èƒç±»å‹æ³¨é‡Šç»“æœ\n",
        "            if \"final_prediction\" in tool_result:\n",
        "                celltype_results.append({\n",
        "                    \"step\": len(celltype_results) + 1,\n",
        "                    \"prediction\": tool_result.get(\"final_prediction\"),\n",
        "                    \"decision_logic\": tool_result.get(\"decision_logic\"),\n",
        "                    \"details\": tool_result.get(\"details\", {})\n",
        "                })\n",
        "\n",
        "if celltype_results:\n",
        "    print(\"ğŸ”¬ ç»†èƒç±»å‹æ³¨é‡Šç»“æœ:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for result in celltype_results:\n",
        "        print(f\"\\nç»“æœ {result['step']}:\")\n",
        "        print(f\"  é¢„æµ‹ç»†èƒç±»å‹: {result['prediction']}\")\n",
        "        print(f\"  å†³ç­–é€»è¾‘: {result['decision_logic']}\")\n",
        "        \n",
        "        if result.get(\"details\"):\n",
        "            details = result[\"details\"]\n",
        "            if \"enrichr\" in details:\n",
        "                enrichr = details[\"enrichr\"]\n",
        "                print(f\"  Enrichr ç»“æœ: {enrichr.get('label', 'N/A')} (ç½®ä¿¡åº¦: {enrichr.get('confidence', 0):.2f})\")\n",
        "            if \"llm_expert\" in details:\n",
        "                llm = details[\"llm_expert\"]\n",
        "                print(f\"  LLM ä¸“å®¶ç»“æœ: {llm.get('label', 'N/A')} (ç½®ä¿¡åº¦: {llm.get('confidence', 0):.2f})\")\n",
        "else:\n",
        "    print(\"âš ï¸ æœªæ‰¾åˆ°ç»†èƒç±»å‹æ³¨é‡Šç»“æœ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ä¿å­˜ç»“æœåˆ°æ–‡ä»¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ç»“æœå·²ä¿å­˜åˆ°: ..\\results\\single_cell_analysis_result.json\n"
          ]
        }
      ],
      "source": [
        "# ä¿å­˜æ‰§è¡Œç»“æœ\n",
        "output_dir = Path(\"../results\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# ä¿å­˜æ‰§è¡Œæ­¥éª¤æ‘˜è¦\n",
        "summary = {\n",
        "    \"total_steps\": len(execution_steps),\n",
        "    \"node_sequence\": [step[\"node\"] for step in execution_steps],\n",
        "    \"final_state\": {\n",
        "        \"final_answer\": final_state.get(\"final_answer\", \"\") if execution_steps else \"\",\n",
        "        \"code_solution\": final_state.get(\"code_solution\", \"\")[:1000] if execution_steps else \"\",  # é™åˆ¶é•¿åº¦\n",
        "        \"rag_context\": final_state.get(\"rag_context\", \"\")[:500] if execution_steps else \"\",\n",
        "        \"final_report\": final_state.get(\"final_report\", \"\")[:500] if execution_steps else \"\"\n",
        "    },\n",
        "    \"generated_codes_count\": len(generated_codes),\n",
        "    \"celltype_results_count\": len(celltype_results)\n",
        "}\n",
        "\n",
        "output_file = output_dir / \"single_cell_analysis_result.json\"\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}\")\n",
        "\n",
        "# ä¿å­˜ç”Ÿæˆçš„ä»£ç \n",
        "if generated_codes:\n",
        "    code_file = output_dir / \"generated_code.py\"\n",
        "    with open(code_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, code_info in enumerate(generated_codes, 1):\n",
        "            f.write(f\"# Code segment {i} (from {code_info['step']})\\n\")\n",
        "            f.write(\"# \" + \"=\"*60 + \"\\n\")\n",
        "            f.write(code_info[\"code\"])\n",
        "            f.write(\"\\n\\n\")\n",
        "    print(f\"âœ… ä»£ç å·²ä¿å­˜åˆ°: {code_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langgraph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
