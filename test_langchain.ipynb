{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606b603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448012d",
   "metadata": {},
   "source": [
    "## langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a5b172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi~', additional_kwargs={}, response_metadata={}, id='21271a68-5dc8-4d61-913e-68a562d9cfe8'),\n",
       "  AIMessage(content='hello world', additional_kwargs={}, response_metadata={}, id='b4889a49-34cf-43c1-9235-363153be5629', tool_calls=[], invalid_tool_calls=[])]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mock_llm(state: MessagesState):\n",
    "    return {\"messages\": [{\"role\": \"ai\", \"content\": \"hello world\"}]}\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(mock_llm)\n",
    "graph.add_edge(START, \"mock_llm\")\n",
    "graph.add_edge(\"mock_llm\", END)\n",
    "graph = graph.compile()\n",
    "\n",
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi~\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3da45",
   "metadata": {},
   "source": [
    "## æµ‹è¯•qwen (langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a709486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å—¨ï¼æˆ‘æ˜¯ä¸€ååšå£«ç”Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    " \n",
    "llm = ChatOpenAI(\n",
    "    # æ ¹æ®è‡ªå·±çš„éœ€æ±‚é…ç½®ï¼Œå¯ä»¥æ˜¯ç¯å¢ƒå˜é‡ï¼Œä¹Ÿå¯ä»¥æ˜¯æ–‡æœ¬å†…å®¹\n",
    "    api_key=\"sk-3e43aba7e80343bc96fb5e7d549837ac\", \n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\"\n",
    ")\n",
    " \n",
    "messages = [\n",
    "    # ç³»ç»Ÿæç¤ºè¯ï¼šå°†è‹±æ–‡ç¿»è¯‘ä¸ºä¸­æ–‡\n",
    "    SystemMessage(\"Translate the following from English into chinese\"),\n",
    "    HumanMessage(\"hi! I'm a PhD student\"),\n",
    "]\n",
    " \n",
    "aimessages = llm.invoke(messages)\n",
    "print(aimessages.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7a93c",
   "metadata": {},
   "source": [
    "## langgraph + qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51fef23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi~ Who are you?', additional_kwargs={}, response_metadata={}, id='25fd6349-dbbc-4b7c-a0be-f8b2c9d6a850'),\n",
       "  AIMessage(content=\"Hello! ğŸ˜Š I'm Qwen, a large-scale language model developed by Alibaba Cloud's Tongyi Lab. I can chat with you, help answer questions, write stories, create documents, code, and even express opinions. I love learning new things and helping out! What would you like to chat about? ğŸŒŸ\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 14, 'total_tokens': 80, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-64f63262-bcc4-9835-9116-cab5261aa827', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bbb67-6e6d-7c32-b7bc-df9fc89e6fb1-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 66, 'total_tokens': 80, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def qwen_llm(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"qwen\", qwen_llm)\n",
    "graph.add_edge(START, \"qwen\")\n",
    "graph.add_edge(\"qwen\", END)\n",
    "graph = graph.compile()\n",
    "\n",
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi~ Who are you?\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fe1ff",
   "metadata": {},
   "source": [
    "## complex langgraph structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815289f",
   "metadata": {},
   "source": [
    "### å¤šèŠ‚ç‚¹ï¼Œç®€å•è¾¹ï¼ˆåŒ agentï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +-----------+   \n",
      " | __start__ |   \n",
      " +-----------+   \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+------------+   \n",
      "| math_agent |   \n",
      "+------------+   \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+-------------+  \n",
      "| check_agent |  \n",
      "+-------------+  \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "  +---------+    \n",
      "  | __end__ |    \n",
      "  +---------+    \n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='1 + 1 = ?', additional_kwargs={}, response_metadata={}, id='4c02d43e-3a7b-4df2-9342-64bd2cd4968a'),\n",
       "  AIMessage(content='2', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 56, 'total_tokens': 57, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-92963ad5-7a51-9b4f-83c4-3a17b78e81c8', 'finish_reason': 'stop', 'logprobs': None}, name='math_agent', id='lc_run--019bbb88-3ddf-70a1-9815-dae2ecd49f27-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 56, 'output_tokens': 1, 'total_tokens': 57, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content='correct', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 78, 'total_tokens': 79, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-7c1f9fc6-483a-9aa2-8f21-44b63536f438', 'finish_reason': 'stop', 'logprobs': None}, name='check_agent', id='lc_run--019bbb88-407c-7813-99e0-a3bb22fad4d8-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 78, 'output_tokens': 1, 'total_tokens': 79, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç®—æ•° agent\n",
    "def math_agent(state: MessagesState):\n",
    "    system_prompt = SystemMessage(\"\"\"\n",
    "    ä½ æ˜¯ä¸€ä¸ªæ™®é€šçš„è®¡ç®—å‘˜ï¼Œä¼šåšåŸºæœ¬çš„æ•°å­¦è¿ç®—ã€‚\n",
    "    è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æˆ–è€…å®¡æ ¸å‘˜çš„å»ºè®®ï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆã€‚ä¸è¦ç»™å‡ºè®¡ç®—è¿‡ç¨‹ã€‚\n",
    "    \"\"\")\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # æ ‡è®° response åç§°\n",
    "    response.name = \"math_agent\"\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# æ£€æŸ¥ agent\n",
    "def check_agent(state: MessagesState):\n",
    "    system_prompt = SystemMessage(\"\"\"\n",
    "    ä½ æ˜¯ä¸€ä¸ªæ•°å­¦å®¶ï¼Œæ“…é•¿æ£€æŸ¥å„ç§æ•°å­¦é—®é¢˜ã€‚\n",
    "    è¯·æ£€æŸ¥ math_agent çš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ã€‚\n",
    "    å¦‚æœæ­£ç¡®ï¼Œè¯·ç»™å‡º \"correct\"ï¼Œå¹¶ç¡®ä¿å›ç­”ä¸­æ²¡æœ‰\"incorrect\"è¿™ä¸ªè¯ã€‚\n",
    "    å¦‚æœé”™è¯¯ï¼Œè¯·ç»™å‡ºæ–°çš„è®¡ç®—å»ºè®®ï¼Œè¯·ç»™å‡º \"incorrect\"ã€‚\n",
    "    \"\"\")\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # æ ‡è®° response åç§°\n",
    "    response.name = \"check_agent\"\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"math_agent\", math_agent)\n",
    "graph.add_node(\"check_agent\", check_agent)\n",
    "graph.add_edge(START, \"math_agent\")\n",
    "graph.add_edge(\"math_agent\", \"check_agent\")\n",
    "graph.add_edge(\"check_agent\", END)\n",
    "graph = graph.compile()\n",
    "\n",
    "# ç”Ÿæˆå›¾çš„æµç¨‹\n",
    "qa_async_ascii = graph.get_graph().print_ascii()\n",
    "print(qa_async_ascii)\n",
    "\n",
    "\n",
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"1 + 1 = ?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504ca3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is 3^{12345} (mod 100)?', additional_kwargs={}, response_metadata={}, id='ed16a73e-9415-4b07-a50c-a25324c0b160'),\n",
       "  AIMessage(content='36', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 58, 'total_tokens': 60, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-707b890c-7506-962b-be5a-e8acd4efba89', 'finish_reason': 'stop', 'logprobs': None}, name='math_agent', id='lc_run--019bbb68-5337-7c13-9f97-42fa3ea91128-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 58, 'output_tokens': 2, 'total_tokens': 60, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content=\"We are asked to compute:\\n\\n$$\\n3^{12345} \\\\mod 100\\n$$\\n\\nand check whether the answer **36** is correct.\\n\\n---\\n\\n### Step 1: Use Euler's theorem\\n\\nEulerâ€™s theorem says that if $\\\\gcd(a, m) = 1$, then:\\n\\n$$\\na^{\\\\phi(m)} \\\\equiv 1 \\\\pmod{m}\\n$$\\n\\nHere, $a = 3$, $m = 100$, and $\\\\gcd(3, 100) = 1$, so we can apply it.\\n\\nCompute $\\\\phi(100)$:\\n\\n$$\\n100 = 2^2 \\\\cdot 5^2 \\\\Rightarrow \\\\phi(100) = 100 \\\\left(1 - \\\\frac{1}{2}\\\\right)\\\\left(1 - \\\\frac{1}{5}\\\\right) = 100 \\\\cdot \\\\frac{1}{2} \\\\cdot \\\\frac{4}{5} = 40\\n$$\\n\\nSo,\\n\\n$$\\n3^{40} \\\\equiv 1 \\\\pmod{100}\\n$$\\n\\nNow reduce the exponent modulo 40:\\n\\n$$\\n12345 \\\\mod 40\\n$$\\n\\nDivide:\\n\\n$$\\n12345 \\\\div 40 = 308.625 \\\\Rightarrow 40 \\\\cdot 308 = 12320 \\\\Rightarrow 12345 - 12320 = 25\\n$$\\n\\nSo,\\n\\n$$\\n12345 \\\\equiv 25 \\\\pmod{40}\\n\\\\Rightarrow 3^{12345} \\\\equiv 3^{25} \\\\pmod{100}\\n$$\\n\\nNow compute $3^{25} \\\\mod 100$.\\n\\n---\\n\\n### Step 2: Compute $3^{25} \\\\mod 100$\\n\\nWe can do this via successive squaring.\\n\\nFirst, compute powers of 3 modulo 100:\\n\\n- $3^1 = 3$\\n- $3^2 = 9$\\n- $3^3 = 27$\\n- $3^4 = 81$\\n- $3^5 = 243 \\\\equiv 43 \\\\pmod{100}$\\n- $3^6 = 3 \\\\cdot 43 = 129 \\\\equiv 29 \\\\pmod{100}$\\n- $3^7 = 3 \\\\cdot 29 = 87$\\n- $3^8 = 3 \\\\cdot 87 = 261 \\\\equiv 61$\\n- $3^9 = 3 \\\\cdot 61 = 183 \\\\equiv 83$\\n- $3^{10} = 3 \\\\cdot 83 = 249 \\\\equiv 49$\\n- $3^{11} = 3 \\\\cdot 49 = 147 \\\\equiv 47$\\n- $3^{12} = 3 \\\\cdot 47 = 141 \\\\equiv 41$\\n- $3^{13} = 3 \\\\cdot 41 = 123 \\\\equiv 23$\\n- $3^{14} = 3 \\\\cdot 23 = 69$\\n- $3^{15} = 3 \\\\cdot 69 = 207 \\\\equiv 7$\\n- $3^{16} = 3 \\\\cdot 7 = 21$\\n- $3^{17} = 3 \\\\cdot 21 = 63$\\n- $3^{18} = 3 \\\\cdot 63 = 189 \\\\equiv 89$\\n- $3^{19} = 3 \\\\cdot 89 = 267 \\\\equiv 67$\\n- $3^{20} = 3 \\\\cdot 67 = 201 \\\\equiv 1 \\\\pmod{100}$ â† Wait! $3^{20} \\\\equiv 1$?\\n\\nWait â€” earlier we said $3^{40} \\\\equiv 1$, but now weâ€™re getting $3^{20} \\\\equiv 1$?\\n\\nLetâ€™s double-check $3^{20}$:\\n\\nWe had:\\n- $3^{10} \\\\equiv 49$\\n- So $3^{20} = (3^{10})^2 = 49^2 = 2401$\\n\\n$$\\n2401 \\\\mod 100 = 1\\n$$\\n\\nYes! So $3^{20} \\\\equiv 1 \\\\pmod{100}$\\n\\nThat means the order is actually 20, not 40. So Euler's theorem gives an exponent (40), but the actual order divides 40, and in this case it's 20.\\n\\nSo since $3^{20} \\\\equiv 1$, then:\\n\\n$$\\n3^{12345} = 3^{25} = 3^{20} \\\\cdot 3^5 \\\\equiv 1 \\\\cdot 3^5 = 243 \\\\equiv 43 \\\\pmod{100}\\n$$\\n\\nWait â€” but earlier we reduced exponent mod 40 and got 25, which is fine, but now we see that the cycle is only 20, so better to reduce exponent mod 20:\\n\\n$$\\n12345 \\\\mod 20 = ?\\n$$\\n\\n$12345 \\\\div 20 = 617.25$, $20 \\\\cdot 617 = 12340$, remainder 5.\\n\\nSo:\\n\\n$$\\n12345 \\\\equiv 5 \\\\pmod{20} \\\\Rightarrow 3^{12345} \\\\equiv 3^5 \\\\pmod{100}\\n$$\\n\\nAnd $3^5 = 243 \\\\Rightarrow 243 \\\\mod 100 = 43$\\n\\nSo final answer is:\\n\\n$$\\n3^{12345} \\\\equiv 43 \\\\pmod{100}\\n$$\\n\\nBut the proposed answer was **36**, which is incorrect.\\n\\n---\\n\\n### âœ… Final Answer:\\n\\n$$\\n\\\\boxed{43}\\n$$\\n\\nThus, the given answer **36** is:\\n\\n**incorrect**\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1385, 'prompt_tokens': 76, 'total_tokens': 1461, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-78237a79-e548-99dd-b096-df3fc0b3ad59', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bbb68-56f2-75d3-ba06-19b9cd3bfc46-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 76, 'output_tokens': 1385, 'total_tokens': 1461, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is 3^{12345} (mod 100)?\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38503b18",
   "metadata": {},
   "source": [
    "### å¤šèŠ‚ç‚¹ï¼Œåˆ¤æ–­è¾¹ï¼ˆåŒ agentï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b745ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState):\n",
    "    \"\"\"\n",
    "    æ ¹æ®å®¡æ ¸ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦é‡æ–°è®¡ç®—ã€‚\n",
    "    è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°ã€‚\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if 'incorrect' in last_message.content:\n",
    "        print(\"å®¡æ ¸ä¸é€šè¿‡ï¼Œæ‰“å›ä¸­...\")\n",
    "        return \"math_agent\"\n",
    "    else:\n",
    "        print(\"å®¡æ ¸é€šè¿‡ï¼Œè¿”å›ç»“æœ...\")\n",
    "        return \"END\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be54f985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å®¡æ ¸ä¸é€šè¿‡ï¼Œæ‰“å›ä¸­...\n",
      "å®¡æ ¸é€šè¿‡ï¼Œè¿”å›ç»“æœ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is 3^{12345} (mod 100)?', additional_kwargs={}, response_metadata={}, id='ab597f2e-5a8a-4d68-ad19-aa66ad3e7ca1'),\n",
       "  AIMessage(content='67', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 68, 'total_tokens': 70, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-394e8017-720e-9cb2-b8e7-137f229b0729', 'finish_reason': 'stop', 'logprobs': None}, name='math_agent', id='lc_run--019bbb88-62d2-73c3-9725-b495b0025f61-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 68, 'output_tokens': 2, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content=\"incorrect\\n\\nTo compute $ 3^{12345} \\\\mod 100 $, we can use Euler's theorem and the Chinese Remainder Theorem.\\n\\nNote that $ \\\\phi(100) = \\\\phi(4 \\\\cdot 25) = \\\\phi(4)\\\\phi(25) = 2 \\\\cdot 20 = 40 $.  \\nSince $ \\\\gcd(3,100) = 1 $, Eulerâ€™s theorem tells us:\\n$$\\n3^{40} \\\\equiv 1 \\\\mod 100\\n$$\\nBut wait â€” this is only valid if $ \\\\phi(100) $ gives the correct exponent, but actually, the Carmichael function $ \\\\lambda(100) $ gives a tighter exponent.\\n\\nLetâ€™s do it properly using **Chinese Remainder Theorem**: compute $ 3^{12345} \\\\mod 4 $ and $ \\\\mod 25 $, then combine.\\n\\n---\\n\\n**Step 1: Modulo 4**\\n\\n$ 3 \\\\equiv -1 \\\\mod 4 $\\n\\nSo:\\n$$\\n3^{12345} \\\\equiv (-1)^{12345} \\\\equiv -1 \\\\equiv 3 \\\\mod 4\\n$$\\n\\n---\\n\\n**Step 2: Modulo 25**\\n\\n$ \\\\phi(25) = 20 $, and $ \\\\gcd(3,25)=1 $, so:\\n$$\\n3^{20} \\\\equiv 1 \\\\mod 25\\n$$\\n\\nNow $ 12345 \\\\mod 20 $:\\n$$\\n12345 \\\\div 20 = 617 \\\\cdot 20 = 12340 \\\\Rightarrow 12345 \\\\equiv 5 \\\\mod 20\\n$$\\n\\nSo:\\n$$\\n3^{12345} \\\\equiv 3^5 \\\\mod 25\\n$$\\n$$\\n3^5 = 243\\n$$\\n$$\\n243 \\\\mod 25 = 243 - 9\\\\cdot25 = 243 - 225 = 18\\n$$\\n\\nSo:\\n$$\\n3^{12345} \\\\equiv 18 \\\\mod 25\\n$$\\n\\n---\\n\\nNow solve the system:\\n$$\\nx \\\\equiv 3 \\\\mod 4 \\\\\\\\\\nx \\\\equiv 18 \\\\mod 25\\n$$\\n\\nLet $ x = 25k + 18 $. Plug into first congruence:\\n$$\\n25k + 18 \\\\equiv 3 \\\\mod 4 \\\\\\\\\\n25k \\\\equiv 1k \\\\mod 4 \\\\Rightarrow k + 18 \\\\equiv 3 \\\\mod 4 \\\\\\\\\\nk \\\\equiv 3 - 18 \\\\mod 4 \\\\Rightarrow k \\\\equiv -15 \\\\equiv 1 \\\\mod 4\\n$$\\n\\nSo $ k = 4m + 1 $\\n\\nThen:\\n$$\\nx = 25(4m + 1) + 18 = 100m + 25 + 18 = 100m + 43\\n$$\\n\\nThus:\\n$$\\nx \\\\equiv 43 \\\\mod 100\\n$$\\n\\nTherefore:\\n$$\\n3^{12345} \\\\equiv 43 \\\\mod 100\\n$$\\n\\nThe correct answer is $ \\\\boxed{43} $, not 67.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 747, 'prompt_tokens': 91, 'total_tokens': 838, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-25d224bf-4358-99fe-9c06-2007183a6975', 'finish_reason': 'stop', 'logprobs': None}, name='check_agent', id='lc_run--019bbb88-6625-7a01-9f99-628cea4bcd66-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 91, 'output_tokens': 747, 'total_tokens': 838, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content='43', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 818, 'total_tokens': 820, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-80bf1feb-aa3d-9973-9a96-1285e3d8e311', 'finish_reason': 'stop', 'logprobs': None}, name='math_agent', id='lc_run--019bbb88-99ed-7d50-a001-a7546b3e4732-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 818, 'output_tokens': 2, 'total_tokens': 820, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content='correct', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 841, 'total_tokens': 842, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-ab3028cd-cfdd-9cda-928a-041c6ffc0276', 'finish_reason': 'stop', 'logprobs': None}, name='check_agent', id='lc_run--019bbb88-9c10-7802-9ef2-f9275967de05-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 841, 'output_tokens': 1, 'total_tokens': 842, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "workflow.add_node(\"math_agent\", math_agent)\n",
    "workflow.add_node(\"check_agent\", check_agent)\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "workflow.add_edge(START, \"math_agent\")\n",
    "workflow.add_edge(\"math_agent\", \"check_agent\")\n",
    "# å¤æ‚åˆ¤æ–­\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"math_agent\": \"math_agent\",\n",
    "        \"END\": END,\n",
    "    },\n",
    ")\n",
    "workflow = workflow.compile()\n",
    "\n",
    "workflow.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is 3^{12345} (mod 100)?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f1bffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +-----------+   \n",
      " | __start__ |   \n",
      " +-----------+   \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+------------+   \n",
      "| math_agent |   \n",
      "+------------+   \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+-------------+  \n",
      "| check_agent |  \n",
      "+-------------+  \n",
      "        .        \n",
      "        .        \n",
      "        .        \n",
      "  +---------+    \n",
      "  | __end__ |    \n",
      "  +---------+    \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆå›¾çš„æµç¨‹å›¾ç‰‡\n",
    "qa_async_ascii = workflow.get_graph().print_ascii()\n",
    "print(qa_async_ascii)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
