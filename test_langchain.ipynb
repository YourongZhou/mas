{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606b603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448012d",
   "metadata": {},
   "source": [
    "## langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a5b172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi~', additional_kwargs={}, response_metadata={}, id='b2edd17a-afcf-425c-82fc-2f92ec2a8c36'),\n",
       "  AIMessage(content='hello world', additional_kwargs={}, response_metadata={}, id='506b97f2-bb9d-49c9-83cb-5c6ccfe42b17', tool_calls=[], invalid_tool_calls=[])]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mock_llm(state: MessagesState):\n",
    "    return {\"messages\": [{\"role\": \"ai\", \"content\": \"hello world\"}]}\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(mock_llm)\n",
    "graph.add_edge(START, \"mock_llm\")\n",
    "graph.add_edge(\"mock_llm\", END)\n",
    "graph = graph.compile()\n",
    "\n",
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi~\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3da45",
   "metadata": {},
   "source": [
    "## æµ‹è¯•qwen (langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a709486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å—¨ï¼æˆ‘æ˜¯ä¸€ååšå£«ç”Ÿã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    " \n",
    "llm = ChatOpenAI(\n",
    "    # æ ¹æ®è‡ªå·±çš„éœ€æ±‚é…ç½®ï¼Œå¯ä»¥æ˜¯ç¯å¢ƒå˜é‡ï¼Œä¹Ÿå¯ä»¥æ˜¯æ–‡æœ¬å†…å®¹\n",
    "    api_key=\"sk-***\", \n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model=\"qwen-plus\"\n",
    ")\n",
    " \n",
    "messages = [\n",
    "    # ç³»ç»Ÿæç¤ºè¯ï¼šå°†è‹±æ–‡ç¿»è¯‘ä¸ºä¸­æ–‡\n",
    "    SystemMessage(\"Translate the following from English into chinese\"),\n",
    "    HumanMessage(\"hi! I'm a PhD student\"),\n",
    "]\n",
    " \n",
    "aimessages = llm.invoke(messages)\n",
    "print(aimessages.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7a93c",
   "metadata": {},
   "source": [
    "## langgraph + qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51fef23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi~ Who are you?', additional_kwargs={}, response_metadata={}, id='df9fa8f3-a413-4f84-a616-eaa336db1048'),\n",
       "  AIMessage(content=\"Hello! I'm Qwen, a large-scale language model independently developed by the Tongyi Lab under Alibaba Group. I can assist you with answering questions, writing, logical reasoning, programming, and more. I can also engage in casual conversations or help with work and study tasks. Feel free to let me know if you need any assistance! ğŸ˜Š\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 14, 'total_tokens': 84, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-cf73a7da-9ece-9e4a-9d46-68d8187aeab2', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bbc52-de5b-73a0-b158-5b8b4fd81858-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 70, 'total_tokens': 84, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def qwen_llm(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"qwen\", qwen_llm)\n",
    "graph.add_edge(START, \"qwen\")\n",
    "graph.add_edge(\"qwen\", END)\n",
    "graph = graph.compile()\n",
    "\n",
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi~ Who are you?\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fe1ff",
   "metadata": {},
   "source": [
    "## complex langgraph structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815289f",
   "metadata": {},
   "source": [
    "### å¤šèŠ‚ç‚¹ï¼Œç®€å•è¾¹ï¼ˆåŒ agentï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3556e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +-----------+   \n",
      " | __start__ |   \n",
      " +-----------+   \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+------------+   \n",
      "| math_agent |   \n",
      "+------------+   \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+-------------+  \n",
      "| check_agent |  \n",
      "+-------------+  \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "  +---------+    \n",
      "  | __end__ |    \n",
      "  +---------+    \n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='1 + 1 = ?', additional_kwargs={}, response_metadata={}, id='71bede86-edd0-4259-a50f-b924656b9fb4'),\n",
       "  AIMessage(content='2', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 56, 'total_tokens': 57, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-703f61e2-82f2-958f-8f18-12858a6361c6', 'finish_reason': 'stop', 'logprobs': None}, name='math_agent', id='lc_run--019bbc52-e4fc-79c0-89e1-bef0b3cc7120-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 56, 'output_tokens': 1, 'total_tokens': 57, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content='correct', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 78, 'total_tokens': 79, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-473ee8a5-3410-9c17-8463-08a2a40dbc77', 'finish_reason': 'stop', 'logprobs': None}, name='check_agent', id='lc_run--019bbc52-e6b6-7900-807c-30e474eaf97d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 78, 'output_tokens': 1, 'total_tokens': 79, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç®—æ•° agent\n",
    "def math_agent(state: MessagesState):\n",
    "    system_prompt = SystemMessage(\"\"\"\n",
    "    ä½ æ˜¯ä¸€ä¸ªæ™®é€šçš„è®¡ç®—å‘˜ï¼Œä¼šåšåŸºæœ¬çš„æ•°å­¦è¿ç®—ã€‚\n",
    "    è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æˆ–è€…å®¡æ ¸å‘˜çš„å»ºè®®ï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆã€‚ä¸è¦ç»™å‡ºè®¡ç®—è¿‡ç¨‹ã€‚\n",
    "    \"\"\")\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # æ ‡è®° response åç§°\n",
    "    response.name = \"math_agent\"\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# æ£€æŸ¥ agent\n",
    "def check_agent(state: MessagesState):\n",
    "    system_prompt = SystemMessage(\"\"\"\n",
    "    ä½ æ˜¯ä¸€ä¸ªæ•°å­¦å®¶ï¼Œæ“…é•¿æ£€æŸ¥å„ç§æ•°å­¦é—®é¢˜ã€‚\n",
    "    è¯·æ£€æŸ¥ math_agent çš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ã€‚\n",
    "    å¦‚æœæ­£ç¡®ï¼Œè¯·ç»™å‡º \"correct\"ï¼Œå¹¶ç¡®ä¿å›ç­”ä¸­æ²¡æœ‰\"incorrect\"è¿™ä¸ªè¯ã€‚\n",
    "    å¦‚æœé”™è¯¯ï¼Œè¯·ç»™å‡ºæ–°çš„è®¡ç®—å»ºè®®ï¼Œè¯·ç»™å‡º \"incorrect\"ã€‚\n",
    "    \"\"\")\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # æ ‡è®° response åç§°\n",
    "    response.name = \"check_agent\"\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"math_agent\", math_agent)\n",
    "graph.add_node(\"check_agent\", check_agent)\n",
    "graph.add_edge(START, \"math_agent\")\n",
    "graph.add_edge(\"math_agent\", \"check_agent\")\n",
    "graph.add_edge(\"check_agent\", END)\n",
    "graph = graph.compile()\n",
    "\n",
    "# ç”Ÿæˆå›¾çš„æµç¨‹\n",
    "qa_async_ascii = graph.get_graph().print_ascii()\n",
    "print(qa_async_ascii)\n",
    "\n",
    "\n",
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"1 + 1 = ?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504ca3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is 3^{12345} (mod 100)?', additional_kwargs={}, response_metadata={}, id='dc6a0cdd-3eee-41ba-81ff-354a6f25254d'),\n",
       "  AIMessage(content='81', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 68, 'total_tokens': 70, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-aa6922a0-026b-9518-b185-02ee907ee09f', 'finish_reason': 'stop', 'logprobs': None}, name='math_agent', id='lc_run--019bbc52-e968-7831-8c53-5885c69e5547-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 68, 'output_tokens': 2, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content=\"incorrect\\n\\nThe value of $ 3^{12345} \\\\mod 100 $ cannot be correctly computed by simple observation due to the large exponent. We must use Euler's theorem or the Carmichael function with modular exponentiation.\\n\\nNote:\\n- $ \\\\phi(100) = \\\\phi(2^2 \\\\cdot 5^2) = 100 \\\\left(1 - \\\\frac{1}{2}\\\\right)\\\\left(1 - \\\\frac{1}{5}\\\\right) = 100 \\\\cdot \\\\frac{1}{2} \\\\cdot \\\\frac{4}{5} = 40 $\\n- Since $ \\\\gcd(3, 100) = 1 $, Euler's theorem tells us $ 3^{40} \\\\equiv 1 \\\\pmod{100} $\\n\\nBut wait: actually, $ \\\\lambda(100) $, the Carmichael function, gives the smallest universal exponent:\\n- $ \\\\lambda(100) = \\\\text{lcm}(\\\\lambda(4), \\\\lambda(25)) = \\\\text{lcm}(2, 20) = 20 $\\nSo $ 3^{20} \\\\equiv 1 \\\\pmod{100} $ if this holds.\\n\\nLetâ€™s verify $ 3^{20} \\\\mod 100 $:\\nWe can compute powers of 3 modulo 100:\\n\\nUse successive squaring:\\n\\n- $ 3^1 = 3 $\\n- $ 3^2 = 9 $\\n- $ 3^4 = (3^2)^2 = 81 $\\n- $ 3^5 = 3^4 \\\\cdot 3 = 81 \\\\cdot 3 = 243 \\\\equiv 43 \\\\mod 100 $\\n- $ 3^{10} = (3^5)^2 = 43^2 = 1849 \\\\equiv 49 \\\\mod 100 $\\n- $ 3^{20} = (3^{10})^2 = 49^2 = 2401 \\\\equiv 1 \\\\mod 100 $\\n\\nYes! $ 3^{20} \\\\equiv 1 \\\\mod 100 $\\n\\nTherefore, $ 3^{12345} = 3^{20 \\\\cdot 617 + 5} = (3^{20})^{617} \\\\cdot 3^5 \\\\equiv 1^{617} \\\\cdot 3^5 \\\\equiv 3^5 \\\\mod 100 $\\n\\nNow $ 3^5 = 243 \\\\Rightarrow 243 \\\\mod 100 = 43 $\\n\\nThus, $ 3^{12345} \\\\mod 100 = 43 $, not 81.\\n\\ncorrect answer is 43.\\n\\nincorrect\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 625, 'prompt_tokens': 91, 'total_tokens': 716, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-dffa1b06-1672-9791-8c74-a63feb56fb19', 'finish_reason': 'stop', 'logprobs': None}, name='check_agent', id='lc_run--019bbc52-ee08-7441-8fde-5ca9124cb0bb-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 91, 'output_tokens': 625, 'total_tokens': 716, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is 3^{12345} (mod 100)?\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38503b18",
   "metadata": {},
   "source": [
    "### å¤šèŠ‚ç‚¹ï¼Œåˆ¤æ–­è¾¹ï¼ˆåŒ agentï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b745ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState):\n",
    "    \"\"\"\n",
    "    æ ¹æ®å®¡æ ¸ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦é‡æ–°è®¡ç®—ã€‚\n",
    "    è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°ã€‚\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if 'incorrect' in last_message.content:\n",
    "        print(\"å®¡æ ¸ä¸é€šè¿‡ï¼Œæ‰“å›ä¸­...\")\n",
    "        return \"math_agent\"\n",
    "    else:\n",
    "        print(\"å®¡æ ¸é€šè¿‡ï¼Œè¿”å›ç»“æœ...\")\n",
    "        return \"END\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be54f985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å®¡æ ¸ä¸é€šè¿‡ï¼Œæ‰“å›ä¸­...\n",
      "å®¡æ ¸é€šè¿‡ï¼Œè¿”å›ç»“æœ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is 3^{12345} (mod 100)?', additional_kwargs={}, response_metadata={}, id='d7c5f388-ef79-4579-8a95-0c9a00966ef8'),\n",
       "  AIMessage(content='81', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 68, 'total_tokens': 70, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-ecf2bd03-29c8-94a8-ad04-639f7bad62dd', 'finish_reason': 'stop', 'logprobs': None}, name='math_agent', id='lc_run--019bbc53-1eb3-7e82-a50a-1c62ffd288c0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 68, 'output_tokens': 2, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content=\"incorrect\\n\\nThe claim that $ 3^{12345} \\\\mod 100 = 81 $ is incorrect.\\n\\nLetâ€™s compute $ 3^{12345} \\\\mod 100 $ properly using Euler's theorem and the Chinese Remainder Theorem.\\n\\n---\\n\\n### Step 1: Use Chinese Remainder Theorem\\nWe compute modulo 4 and modulo 25, then combine:\\n\\n#### Modulo 4:\\n$ 3 \\\\equiv -1 \\\\mod 4 $\\n\\nSo:\\n$ 3^{12345} \\\\equiv (-1)^{12345} \\\\equiv -1 \\\\equiv 3 \\\\mod 4 $\\n\\n#### Modulo 25:\\nUse Euler's theorem. $ \\\\phi(25) = 20 $, and $ \\\\gcd(3,25)=1 $, so:\\n$ 3^{20} \\\\equiv 1 \\\\mod 25 $\\n\\nNow:\\n$ 12345 \\\\mod 20 = 5 $, since $ 12345 = 617 \\\\times 20 + 5 $\\n\\nSo:\\n$ 3^{12345} \\\\equiv 3^5 \\\\mod 25 $\\n\\nCompute $ 3^5 = 243 $\\n\\n$ 243 \\\\mod 25 = 243 - 9 \\\\times 25 = 243 - 225 = 18 $\\n\\nSo:\\n$ 3^{12345} \\\\equiv 18 \\\\mod 25 $\\n\\n---\\n\\n### Step 2: Solve the system:\\nWe want $ x \\\\equiv 3 \\\\mod 4 $  \\nand $ x \\\\equiv 18 \\\\mod 25 $\\n\\nLet $ x = 25k + 18 $. Plug into first congruence:\\n\\n$ 25k + 18 \\\\equiv 3 \\\\mod 4 $\\n\\n$ 25k \\\\equiv k \\\\mod 4 $, $ 18 \\\\equiv 2 \\\\mod 4 $\\n\\nSo:\\n$ k + 2 \\\\equiv 3 \\\\mod 4 \\\\Rightarrow k \\\\equiv 1 \\\\mod 4 $\\n\\nSo $ k = 4m + 1 $, then:\\n$ x = 25(4m + 1) + 18 = 100m + 25 + 18 = 100m + 43 $\\n\\nThus:\\n$ x \\\\equiv 43 \\\\mod 100 $\\n\\n---\\n\\n### Final Answer:\\n$ 3^{12345} \\\\mod 100 = 43 $\\n\\nSo the correct answer is **43**, not 81.\\n\\n**incorrect**\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 584, 'prompt_tokens': 91, 'total_tokens': 675, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-b3cf62e7-966b-9d12-a8be-3778a7b5a4a8', 'finish_reason': 'stop', 'logprobs': None}, name='check_agent', id='lc_run--019bbc53-2059-7902-9f91-15807ae0b70f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 91, 'output_tokens': 584, 'total_tokens': 675, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content='43', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 655, 'total_tokens': 657, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-0c03fc89-6aeb-9229-ab66-17cae2753b23', 'finish_reason': 'stop', 'logprobs': None}, name='math_agent', id='lc_run--019bbc53-4ec2-7970-b749-c7e7a95a64d9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 655, 'output_tokens': 2, 'total_tokens': 657, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  AIMessage(content='correct', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 678, 'total_tokens': 679, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-3309e93d-12fe-9f1d-ab37-113e08acf436', 'finish_reason': 'stop', 'logprobs': None}, name='check_agent', id='lc_run--019bbc53-512e-79e0-8e6a-f7fab40f7b31-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 678, 'output_tokens': 1, 'total_tokens': 679, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "workflow.add_node(\"math_agent\", math_agent)\n",
    "workflow.add_node(\"check_agent\", check_agent)\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "workflow.add_edge(START, \"math_agent\")\n",
    "workflow.add_edge(\"math_agent\", \"check_agent\")\n",
    "# å¤æ‚åˆ¤æ–­\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"math_agent\": \"math_agent\",\n",
    "        \"END\": END,\n",
    "    },\n",
    ")\n",
    "workflow = workflow.compile()\n",
    "\n",
    "workflow.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is 3^{12345} (mod 100)?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1bffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +-----------+   \n",
      " | __start__ |   \n",
      " +-----------+   \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+------------+   \n",
      "| math_agent |   \n",
      "+------------+   \n",
      "        .        \n",
      "        .        \n",
      "        .        \n",
      "+-------------+  \n",
      "| check_agent |  \n",
      "+-------------+  \n",
      "        .        \n",
      "        .        \n",
      "        .        \n",
      "  +---------+    \n",
      "  | __end__ |    \n",
      "  +---------+    \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆå›¾çš„æµç¨‹å›¾ç‰‡\n",
    "qa_async_ascii = workflow.get_graph().print_ascii()\n",
    "print(qa_async_ascii)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
